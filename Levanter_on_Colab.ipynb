{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lancelotblanchard/levanterForAnticipation/blob/main/Levanter_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**/!\\ IMPORTANT!! MAKE SURE THAT YOU ARE USING A GPU INSTANCE (NOT A CPU, NOT A TPU) /!\\**"
      ],
      "metadata": {
        "id": "KBGFTWO0jJaP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebUqRjWloJSl",
        "outputId": "f90bc3ca-a83a-4716-c190-09054682a5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount to google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65XhHjD4KlkJ"
      },
      "source": [
        "# Clone Levanter repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UybkxzZAKhcC"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/lancelotblanchard/levanterForAnticipation.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-inZa7HxqNZ4"
      },
      "source": [
        "# If using CPU, use this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xBo4jUSqRcz"
      },
      "outputs": [],
      "source": [
        "!pip install -U jax==0.4.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkpEzs8uo78v"
      },
      "source": [
        "# If using TPU, use this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY5MXWSRo6F0"
      },
      "outputs": [],
      "source": [
        "!pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkghOrDpo_ps"
      },
      "source": [
        "#If using GPU, use this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBklxokJpxGv"
      },
      "source": [
        "# Install Levanter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TENTATIVE\n",
        "!pip install -U \"jax[cuda12_pip]\"==0.4.18 optax==0.1.7 scipy==1.11.3 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install -e /content/levanterForAnticipation\n",
        "!pip install haliax==1.2"
      ],
      "metadata": {
        "id": "8xJLA5vl8I0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG8Rl-M9d-Jw"
      },
      "source": [
        "**/!\\ AT THIS POINT, RESTART RUNTIME /!\\**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35QbvLHppG-u"
      },
      "source": [
        "# Train the gpt2 small"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSsiyCW0BUYt",
        "outputId": "7065419f-94a1-4347-9f24-aac1d2876614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.4.1+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: accelerate, fastai, timm, torchaudio, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfELE7EoodGY"
      },
      "outputs": [],
      "source": [
        "# Delete JAX Plugins\n",
        "!rm -rf /usr/local/lib/python3.10/dist-packages/jax_cuda12_pjrt-0.4.33.dist-info/\n",
        "!rm -rf /usr/local/lib/python3.10/dist-packages/jax_cuda12_plugin-0.4.33.dist-info/\n",
        "!rm -rf /usr/local/lib/python3.10/dist-packages/jax_cuda12_plugin/\n",
        "!rm -rf /usr/local/lib/python3.10/dist-packages/jax_plugins/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkJpW8AggSjF",
        "outputId": "d021cece-5c4a-471e-a59d-a2aafc40606b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cpu': <jaxlib.xla_extension.Client at 0x78f908205c70>,\n",
              " 'cuda': <jaxlib.xla_extension.Client at 0x78f908110db0>}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import jax._src.xla_bridge as xlab\n",
        "\n",
        "xlab.backends()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, replace `WANDB_API_KEY` with a W&B API key found here: https://wandb.ai/settings#api."
      ],
      "metadata": {
        "id": "3RRxqumiipNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login WANDB_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMMyIbye7zUW",
        "outputId": "bf77cdfb-3b67-446f-ab80-b997363f6140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q76utOlUj2Hg",
        "outputId": "8a55e003-9ea6-4370-c403-f2d9ff276195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "config.json: 100% 665/665 [00:00<00:00, 4.46MB/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 205kB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 8.40MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.48MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 17.1MB/s]\n",
            "INFO:levanter.distributed:Not initializing jax.distributed because no distributed config was provided, and no cluster was detected.\n",
            "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA\n",
            "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
            "INFO:levanter.trainer:Setting run id to 681y1b02\n",
            "INFO:levanter.distributed:No auto-discovered ray address found. Using default ray.init()\n",
            "INFO:levanter.distributed:ray.init(address=None, namespace='levanter', **{})\n",
            "2024-10-19 18:25:57,342\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "INFO:levanter.logging:Setting wandb code_dir to /content/levanterForAnticipation\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlancelotblanchard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20241019_182559-681y1b02\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-bird-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/lancelotblanchard/uncategorized\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/lancelotblanchard/uncategorized/runs/681y1b02\u001b[0m\n",
            "2024-10-19T18:26:01 - 0 - levanter.data.shard_cache - shard_cache.py:1030 - INFO :: Loading cache from cache/validation\n",
            "2024-10-19T18:26:01 - 0 - levanter.data.text - text.py:300 - INFO :: new cache format not found, trying to convert from old format\n",
            "2024-10-19T18:26:01 - 0 - levanter.data.text - text.py:309 - WARNING :: old cache format not found, creating new cache\n",
            "2024-10-19T18:26:01 - 0 - levanter.data.text - text.py:611 - INFO :: Building cache for validation...\n",
            "2024-10-19T18:26:01 - 0 - levanter.data.shard_cache - shard_cache.py:1030 - INFO :: Loading cache from cache/validation\n",
            "\u001b[36m(ChunkCacheBuilder pid=2414)\u001b[0m INFO:levanter.data.shard_cache:Starting cache build for 1 shards\n",
            "\u001b[36m(_produce_cache_for_shard pid=2652)\u001b[0m INFO:levanter.data.shard_cache:Starting shard tokenized-events-Validation_txt\n",
            "\u001b[36m(_produce_cache_for_shard pid=2652)\u001b[0m INFO:levanter.data.shard_cache:Starting to get rows for shard tokenized-events-Validation_txt\n",
            "2024-10-19T18:26:26 - 0 - preprocessing.validation - shard_cache.py:534 - INFO ::  done: Shards: 0 | Chunks: 1 | Docs: 98\n",
            "2024-10-19T18:26:26 - 0 - preprocessing.validation - shard_cache.py:534 - INFO ::  done: Shards: 1 | Chunks: 1 | Docs: 98\n",
            "2024-10-19T18:26:26 - 0 - preprocessing.validation - shard_cache.py:541 - INFO :: Cache creation finished\n",
            "\u001b[36m(ChunkCacheBroker pid=2413)\u001b[0m INFO:levanter.data.shard_cache:Finalizing cache cache/validation...\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.text - text.py:274 - INFO :: Cache cache/validation is complete.\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.shard_cache - shard_cache.py:1030 - INFO :: Loading cache from cache/train\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.text - text.py:300 - INFO :: new cache format not found, trying to convert from old format\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.text - text.py:309 - WARNING :: old cache format not found, creating new cache\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.text - text.py:611 - INFO :: Building cache for train...\n",
            "2024-10-19T18:26:26 - 0 - levanter.data.shard_cache - shard_cache.py:1030 - INFO :: Loading cache from cache/train\n",
            "2024-10-19T18:26:31 - 0 - levanter.data.text - text.py:276 - INFO :: Cache cache/train is incomplete. This will block until at least one chunk per process is complete.\n",
            "2024-10-19T18:26:31 - 0 - levanter.checkpoint - checkpoint.py:368 - WARNING :: No checkpoints found in /content/drive/MyDrive/Main Projects/Jordan Rudess Collaboration/levanterData/checkpoints/681y1b02\n",
            "2024-10-19T18:26:33 - 0 - __main__ - train_lm.py:123 - INFO :: No training checkpoint found. Initializing model from HF checkpoint 'stanford-crfm/music-small-800k'\n",
            "pytorch_model.bin:  25% 126M/512M [00:02<00:07, 51.9MB/s]\u001b[36m(_produce_cache_for_shard pid=2652)\u001b[0m INFO:levanter.data.shard_cache:Starting shard tokenized-events-Train_txt\n",
            "\u001b[36m(_produce_cache_for_shard pid=2652)\u001b[0m INFO:levanter.data.shard_cache:Starting to get rows for shard tokenized-events-Train_txt\n",
            "\u001b[36m(ChunkCacheBuilder pid=2885)\u001b[0m INFO:levanter.data.shard_cache:Starting cache build for 1 shards\n",
            "pytorch_model.bin: 100% 512M/512M [00:10<00:00, 49.0MB/s]\n",
            "/content/levanterForAnticipation/src/levanter/compat/hf_checkpoints.py:397: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=device)\n",
            "config.json: 100% 1.96k/1.96k [00:00<00:00, 3.08MB/s]\n",
            "train:   0% 0/2001 [00:00<?, ?it/s]2024-10-19T18:27:05 - 0 - preprocessing.train - shard_cache.py:534 - INFO ::  done: Shards: 0 | Chunks: 1 | Docs: 4880\n",
            "2024-10-19T18:27:05 - 0 - preprocessing.train - shard_cache.py:534 - INFO ::  done: Shards: 1 | Chunks: 1 | Docs: 4880\n",
            "2024-10-19T18:27:05 - 0 - preprocessing.train - shard_cache.py:534 - INFO ::  done: Shards: 1 | Chunks: 1 | Docs: 4880\n",
            "\u001b[36m(ChunkCacheBroker pid=2759)\u001b[0m INFO:levanter.data.shard_cache:Finalizing cache cache/train...2024-10-19T18:27:05 - 0 - preprocessing.train - shard_cache.py:541 - INFO :: Cache creation finished\n",
            "\n",
            "train:   0% 1/2001 [04:34<152:27:35, 274.43s/it, loss=1.25]\n",
            "eval : 0it [00:00, ?it/s]\u001b[A\n",
            "eval : 0it [00:02, ?it/s, loss=1.25]\u001b[A\n",
            "eval : 1it [00:02,  2.63s/it, loss=1.25]\u001b[A\n",
            "eval : 1it [00:02,  2.63s/it, loss=1.26]\u001b[A\n",
            "eval : 2it [00:02,  1.17s/it, loss=1.26]\u001b[A\n",
            "eval : 2it [00:02,  1.17s/it, loss=1.23]\u001b[A\n",
            "eval : 3it [00:02,  1.43it/s, loss=1.23]\u001b[A\n",
            "eval : 3it [00:03,  1.43it/s, loss=1.25]\u001b[A\n",
            "eval : 4it [00:03,  2.09it/s, loss=1.25]\u001b[A\n",
            "eval : 4it [00:03,  2.09it/s, loss=1.23]\u001b[A\n",
            "eval : 5it [00:03,  2.80it/s, loss=1.23]\u001b[A\n",
            "eval : 5it [00:03,  2.80it/s, loss=1.23]\u001b[A\n",
            "eval : 6it [00:03,  3.53it/s, loss=1.23]\u001b[A\n",
            "eval : 6it [00:03,  3.53it/s, loss=1.25]\u001b[A\n",
            "eval : 7it [00:03,  4.19it/s, loss=1.25]\u001b[A\n",
            "eval : 7it [00:03,  4.19it/s, loss=1.26]\u001b[A\n",
            "eval : 8it [00:03,  4.83it/s, loss=1.26]\u001b[A\n",
            "eval : 8it [00:03,  4.83it/s, loss=1.25]\u001b[A\n",
            "eval : 9it [00:03,  5.37it/s, loss=1.25]\u001b[A\n",
            "eval : 9it [00:03,  5.37it/s, loss=1.26]\u001b[A\n",
            "eval : 10it [00:03,  5.81it/s, loss=1.26]\u001b[A\n",
            "eval : 10it [00:04,  5.81it/s, loss=1.25]\u001b[A\n",
            "eval : 11it [00:04,  6.14it/s, loss=1.25]\u001b[A\n",
            "eval : 11it [00:04,  6.14it/s, loss=1.23]\u001b[A\n",
            "eval : 12it [00:04,  6.41it/s, loss=1.23]\u001b[A\n",
            "eval : 12it [00:04,  6.41it/s, loss=1.23]\u001b[A\n",
            "eval : 13it [00:04,  6.59it/s, loss=1.23]\u001b[A\n",
            "eval : 13it [00:04,  6.59it/s, loss=1.23]\u001b[A\n",
            "eval : 14it [00:04,  6.70it/s, loss=1.23]\u001b[A\n",
            "eval : 14it [00:04,  6.70it/s, loss=1.23]\u001b[A\n",
            "eval : 15it [00:04,  6.80it/s, loss=1.23]\u001b[A\n",
            "eval : 15it [00:04,  6.80it/s, loss=1.23]\u001b[A\n",
            "eval : 16it [00:04,  6.90it/s, loss=1.23]\u001b[A\n",
            "eval : 16it [00:04,  6.90it/s, loss=1.23]\u001b[A\n",
            "eval : 17it [00:04,  6.95it/s, loss=1.23]\u001b[A\n",
            "eval : 17it [00:05,  6.95it/s, loss=1.23]\u001b[A\n",
            "eval : 18it [00:05,  7.01it/s, loss=1.23]\u001b[A\n",
            "eval : 18it [00:05,  7.01it/s, loss=1.24]\u001b[A\n",
            "eval : 19it [00:05,  7.05it/s, loss=1.24]\u001b[A\n",
            "eval : 19it [00:05,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 20it [00:05,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 20it [00:05,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 21it [00:05,  7.03it/s, loss=1.23]\u001b[A\n",
            "eval : 21it [00:05,  7.03it/s, loss=1.23]\u001b[A\n",
            "eval : 22it [00:05,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 22it [00:05,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 23it [00:05,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 23it [00:05,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 24it [00:05,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 24it [00:06,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 25it [00:06,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 25it [00:06,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 26it [00:06,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 26it [00:06,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 27it [00:06,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 27it [00:06,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 28it [00:06,  7.07it/s, loss=1.23]\u001b[A\n",
            "eval : 28it [00:06,  7.07it/s, loss=1.22]\u001b[A\n",
            "eval : 29it [00:06,  7.07it/s, loss=1.22]\u001b[A\n",
            "eval : 29it [00:06,  7.07it/s, loss=1.22]\u001b[A\n",
            "eval : 30it [00:06,  7.08it/s, loss=1.22]\u001b[A\n",
            "eval : 30it [00:06,  7.08it/s, loss=1.22]\u001b[A\n",
            "eval : 31it [00:06,  7.05it/s, loss=1.22]\u001b[A\n",
            "eval : 31it [00:07,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 32it [00:07,  7.03it/s, loss=1.23]\u001b[A\n",
            "eval : 32it [00:07,  7.03it/s, loss=1.23]\u001b[A\n",
            "eval : 33it [00:07,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 33it [00:07,  7.04it/s, loss=1.22]\u001b[A\n",
            "eval : 34it [00:07,  7.02it/s, loss=1.22]\u001b[A\n",
            "eval : 34it [00:07,  7.02it/s, loss=1.22]\u001b[A\n",
            "eval : 35it [00:07,  7.04it/s, loss=1.22]\u001b[A\n",
            "eval : 35it [00:07,  7.04it/s, loss=1.22]\u001b[A\n",
            "eval : 36it [00:07,  7.04it/s, loss=1.22]\u001b[A\n",
            "eval : 36it [00:07,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 37it [00:07,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 37it [00:07,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 38it [00:07,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 38it [00:08,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 39it [00:08,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 39it [00:08,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 40it [00:08,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 40it [00:08,  7.04it/s, loss=1.23]\u001b[A\n",
            "eval : 41it [00:08,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 41it [00:08,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 42it [00:08,  7.08it/s, loss=1.23]\u001b[A\n",
            "eval : 42it [00:08,  7.08it/s, loss=1.22]\u001b[A\n",
            "eval : 43it [00:08,  7.07it/s, loss=1.22]\u001b[A\n",
            "eval : 43it [00:08,  7.07it/s, loss=1.23]\u001b[A\n",
            "eval : 44it [00:08,  7.07it/s, loss=1.23]\u001b[A\n",
            "eval : 44it [00:08,  7.07it/s, loss=1.23]\u001b[A\n",
            "eval : 45it [00:08,  7.08it/s, loss=1.23]\u001b[A\n",
            "eval : 45it [00:08,  7.08it/s, loss=1.23]\u001b[A\n",
            "eval : 46it [00:08,  7.10it/s, loss=1.23]\u001b[A\n",
            "eval : 46it [00:09,  7.10it/s, loss=1.23]\u001b[A\n",
            "eval : 47it [00:09,  7.08it/s, loss=1.23]\u001b[A\n",
            "eval : 47it [00:09,  7.08it/s, loss=1.23]\u001b[A\n",
            "eval : 48it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 48it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 49it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 49it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 50it [00:09,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 50it [00:09,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 51it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 51it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 52it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 52it [00:09,  7.05it/s, loss=1.23]\u001b[A\n",
            "eval : 53it [00:09,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 53it [00:10,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 54it [00:10,  7.06it/s, loss=1.23]\u001b[A\n",
            "eval : 54it [00:10,  7.06it/s, loss=1.22]\u001b[A\n",
            "eval : 55it [00:10,  7.06it/s, loss=1.22]\u001b[A\n",
            "eval : 55it [00:10,  7.06it/s, loss=1.22]\u001b[A\n",
            "eval : 56it [00:10,  7.05it/s, loss=1.22]\u001b[A\n",
            "eval : 56it [00:10,  7.05it/s, loss=1.22]\u001b[A\n",
            "eval : 57it [00:10,  7.06it/s, loss=1.22]\u001b[A\n",
            "eval : 57it [00:10,  7.06it/s, loss=1.21]\u001b[A\n",
            "eval : 58it [00:10,  7.06it/s, loss=1.21]\u001b[A\n",
            "eval : 58it [00:10,  7.06it/s, loss=1.21]\u001b[A\n",
            "eval : 59it [00:10,  7.05it/s, loss=1.21]\u001b[A\n",
            "eval : 59it [00:10,  7.05it/s, loss=1.21]\u001b[A\n",
            "eval : 60it [00:10,  7.06it/s, loss=1.21]\u001b[A\n",
            "eval : 60it [00:11,  7.06it/s, loss=1.2] \u001b[A\n",
            "eval : 61it [00:11,  7.06it/s, loss=1.2]\u001b[A\n",
            "eval : 61it [00:11,  7.06it/s, loss=1.2]\u001b[A\n",
            "eval : 62it [00:11,  7.03it/s, loss=1.2]\u001b[A\n",
            "eval : 62it [00:11,  7.03it/s, loss=1.2]\u001b[A\n",
            "eval : 63it [00:11,  7.07it/s, loss=1.2]\u001b[A\n",
            "eval : 63it [00:11,  7.07it/s, loss=1.2]\u001b[A\n",
            "eval : 64it [00:11,  7.06it/s, loss=1.2]\u001b[A\n",
            "eval : 64it [00:11,  7.06it/s, loss=1.2]\u001b[A\n",
            "eval : 65it [00:11,  7.06it/s, loss=1.2]\u001b[A\n",
            "eval : 65it [00:11,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 66it [00:11,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 66it [00:11,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 67it [00:11,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 67it [00:12,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 68it [00:12,  7.07it/s, loss=1.19]\u001b[A\n",
            "eval : 68it [00:12,  7.07it/s, loss=1.19]\u001b[A\n",
            "eval : 69it [00:12,  7.07it/s, loss=1.19]\u001b[A\n",
            "eval : 69it [00:12,  7.07it/s, loss=1.19]\u001b[A\n",
            "eval : 70it [00:12,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 70it [00:12,  7.06it/s, loss=1.19]\u001b[A\n",
            "eval : 71it [00:12,  7.04it/s, loss=1.19]\u001b[A\n",
            "eval : 71it [00:12,  7.04it/s, loss=1.18]\u001b[A\n",
            "eval : 72it [00:12,  7.04it/s, loss=1.18]\u001b[A\n",
            "eval : 72it [00:12,  7.04it/s, loss=1.18]\u001b[A\n",
            "eval : 73it [00:12,  7.05it/s, loss=1.18]\u001b[A\n",
            "eval : 73it [00:12,  7.05it/s, loss=1.18]\u001b[A\n",
            "eval : 74it [00:12,  7.07it/s, loss=1.18]\u001b[A\n",
            "eval : 74it [00:13,  7.07it/s, loss=1.18]\u001b[A\n",
            "eval : 75it [00:13,  7.07it/s, loss=1.18]\u001b[A\n",
            "eval : 75it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 76it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 76it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 77it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 77it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 78it [00:13,  7.06it/s, loss=1.17]\u001b[A\n",
            "eval : 78it [00:13,  7.06it/s, loss=1.17]\u001b[A\n",
            "eval : 79it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 79it [00:13,  7.07it/s, loss=1.17]\u001b[A\n",
            "eval : 80it [00:13,  7.06it/s, loss=1.17]\u001b[A\n",
            "eval : 80it [00:13,  7.06it/s, loss=1.16]\u001b[A\n",
            "eval : 81it [00:13,  7.07it/s, loss=1.16]\u001b[A\n",
            "eval : 81it [00:14,  7.07it/s, loss=1.16]\u001b[A\n",
            "eval : 82it [00:14,  7.06it/s, loss=1.16]\u001b[A\n",
            "eval : 82it [00:14,  7.06it/s, loss=1.16]\u001b[A\n",
            "eval : 83it [00:14,  7.08it/s, loss=1.16]\u001b[A\n",
            "eval : 83it [00:14,  7.08it/s, loss=1.16]\u001b[A\n",
            "eval : 84it [00:14,  7.05it/s, loss=1.16]\u001b[A\n",
            "eval : 84it [00:14,  7.05it/s, loss=1.16]\u001b[A\n",
            "eval : 85it [00:14,  7.06it/s, loss=1.16]\u001b[A\n",
            "eval : 85it [00:14,  7.06it/s, loss=1.16]\u001b[A\n",
            "eval : 86it [00:14,  7.02it/s, loss=1.16]\u001b[A\n",
            "eval : 86it [00:14,  7.02it/s, loss=1.16]\u001b[A\n",
            "eval : 87it [00:14,  7.00it/s, loss=1.16]\u001b[A\n",
            "eval : 87it [00:14,  7.00it/s, loss=1.16]\u001b[A\n",
            "eval : 88it [00:14,  7.03it/s, loss=1.16]\u001b[A\n",
            "eval : 88it [00:15,  7.03it/s, loss=1.15]\u001b[A\n",
            "eval : 89it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 89it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 90it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 90it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 91it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 91it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 92it [00:15,  7.05it/s, loss=1.15]\u001b[A\n",
            "eval : 92it [00:15,  7.05it/s, loss=1.15]\u001b[A\n",
            "eval : 93it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 93it [00:15,  7.06it/s, loss=1.15]\u001b[A\n",
            "eval : 94it [00:15,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 94it [00:15,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 95it [00:15,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 95it [00:16,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 96it [00:16,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 96it [00:16,  7.07it/s, loss=1.15]\u001b[A\n",
            "eval : 97it [00:16,  7.05it/s, loss=1.15]\u001b[A\n",
            "eval : 97it [00:16,  7.05it/s, loss=1.14]\u001b[A\n",
            "eval : 98it [00:16,  7.06it/s, loss=1.14]\u001b[A\n",
            "                                         \u001b[A2024-10-19T18:31:40 - 0 - levanter.callbacks - callbacks.py:69 - INFO :: validation loss: 1.145\n",
            "train:   0% 3/2001 [13:09<144:23:02, 260.15s/it, loss=1.23]*** SIGTERM received at time=1729363202 on cpu 1 ***\n",
            "PC: @     0x795902f3cc9b  (unknown)  sched_yield\n",
            "    @     0x795902e76520   24744928  (unknown)\n",
            "    @     0x7958379033d5         48  (unknown)\n",
            "    @     0x795837636adc        112  (unknown)\n",
            "    @     0x795837636d7f        320  (unknown)\n",
            "    @     0x79583763c33a       1136  (unknown)\n",
            "    @     0x795837735eeb        240  (unknown)\n",
            "    @     0x7958fee7575f        464  stream_executor::gpu::GpuDriver::GraphLaunch()\n",
            "    @     0x7958f9368f1e        512  stream_executor::gpu::OwnedGpuGraphExec::Launch()\n",
            "    @     0x7958f92eb963       1344  xla::gpu::LaunchGraph()\n",
            "    @     0x7958f92e0f60       1232  xla::runtime::CustomCallHandler<>::call()\n",
            "    @     0x7958f92e7c72       2080  xla::gpu::Launch()\n",
            "    @     0x795827ec4fcd      10448  (unknown)\n",
            "    @     0x7958f95a64b7        144  xla::runtime::Executable::Execute()\n",
            "    @     0x7958f91e7f6d       1984  xla::gpu::GpuRuntimeExecutable::Execute()\n",
            "    @     0x7958f8875e3e        480  xla::gpu::GpuExecutable::ExecuteThunksOrXlaRuntime()\n",
            "    @     0x7958f888102a       2496  xla::gpu::GpuExecutable::ExecuteAsyncOnStreamImpl()\n",
            "    @     0x7958f88820a0        112  xla::gpu::GpuExecutable::ExecuteAsyncOnStream()\n",
            "    @     0x7958fca8c6bd       1552  xla::Executable::ExecuteAsyncOnStreamWrapper()\n",
            "    @     0x7958f7e8e0e4       2560  xla::LocalExecutable::RunAsync()\n",
            "    @     0x7958f7e8ebb5        288  xla::LocalExecutable::RunAsync()\n",
            "    @     0x7958f7e569a0       2800  xla::PjRtStreamExecutorLoadedExecutable::EnqueueExecution()\n",
            "    @     0x7958f7e5880f       3408  xla::PjRtStreamExecutorLoadedExecutable::ExecuteHelper()\n",
            "    @     0x7958f7e5ae27        928  xla::PjRtStreamExecutorLoadedExecutable::Execute()\n",
            "    @     0x7958f7d86e07       1328  xla::ifrt::PjRtLoadedExecutable::Execute()\n",
            "    @     0x7958f705a57f       1728  jax::(anonymous namespace)::PjitFunction::Call()\n",
            "    @     0x7958f705be03        288  PjitFunction_tp_vectorcall\n",
            "    @     0x5b5caf5e78cc  (unknown)  _PyEval_EvalFrameDefault\n",
            "    @ ... and at least 10 more frames\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440: *** SIGTERM received at time=1729363203 on cpu 1 ***\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440: PC: @     0x795902f3cc9b  (unknown)  sched_yield\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x795902e76520   24744928  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958379033d5         48  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x795837636adc        112  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x795837636d7f        320  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x79583763c33a       1136  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x795837735eeb        240  (unknown)\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958fee7575f        464  stream_executor::gpu::GpuDriver::GraphLaunch()\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958f9368f1e        512  stream_executor::gpu::OwnedGpuGraphExec::Launch()\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958f92eb963       1344  xla::gpu::LaunchGraph()\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958f92e0f60       1232  xla::runtime::CustomCallHandler<>::call()\n",
            "[2024-10-19 18:40:03,193 E 2201 2201] logging.cc:440:     @     0x7958f92e7c72       2080  xla::gpu::Launch()\n",
            "[2024-10-19 18:40:03,197 E 2201 2201] logging.cc:440:     @     0x795827ec4fcd      10448  (unknown)\n",
            "[2024-10-19 18:40:03,197 E 2201 2201] logging.cc:440:     @     0x7958f95a64b7        144  xla::runtime::Executable::Execute()\n",
            "[2024-10-19 18:40:03,197 E 2201 2201] logging.cc:440:     @     0x7958f91e7f6d       1984  xla::gpu::GpuRuntimeExecutable::Execute()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f8875e3e        480  xla::gpu::GpuExecutable::ExecuteThunksOrXlaRuntime()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f888102a       2496  xla::gpu::GpuExecutable::ExecuteAsyncOnStreamImpl()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f88820a0        112  xla::gpu::GpuExecutable::ExecuteAsyncOnStream()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958fca8c6bd       1552  xla::Executable::ExecuteAsyncOnStreamWrapper()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7e8e0e4       2560  xla::LocalExecutable::RunAsync()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7e8ebb5        288  xla::LocalExecutable::RunAsync()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7e569a0       2800  xla::PjRtStreamExecutorLoadedExecutable::EnqueueExecution()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7e5880f       3408  xla::PjRtStreamExecutorLoadedExecutable::ExecuteHelper()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7e5ae27        928  xla::PjRtStreamExecutorLoadedExecutable::Execute()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f7d86e07       1328  xla::ifrt::PjRtLoadedExecutable::Execute()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f705a57f       1728  jax::(anonymous namespace)::PjitFunction::Call()\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x7958f705be03        288  PjitFunction_tp_vectorcall\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @     0x5b5caf5e78cc  (unknown)  _PyEval_EvalFrameDefault\n",
            "[2024-10-19 18:40:03,198 E 2201 2201] logging.cc:440:     @ ... and at least 10 more frames\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python -m levanter.main.train_lm --config_path /content/drive/MyDrive/YOUR_LOCATION_TO_CONFIG_FILE.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hc7btlJe5hUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-inZa7HxqNZ4",
        "RkpEzs8uo78v"
      ],
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}